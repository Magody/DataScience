{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  item  rating\n",
       "0     0     0     5.0\n",
       "1     0     2     4.0\n",
       "2     1     0     5.0\n",
       "3     1     1     1.0\n",
       "4     2     3     5.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ratings:pd.DataFrame = pd.DataFrame(data={\n",
    "    \"user\":   [0,0,1,1,2,3,3,4,4,5], # 0-index\n",
    "    \"item\":   [0,2,0,1,3,0,2,4,1,2], # 0-index\n",
    "    \"rating\": [5,4,5,1,5,5,5,2,3,4]\n",
    "})\n",
    "\n",
    "df_ratings[\"rating\"] = df_ratings[\"rating\"].astype(\"float32\")\n",
    "\n",
    "df_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import SparseTensor\n",
    "from lib.similarity_measures import *\n",
    "\n",
    "\n",
    "def buildSparseTensorRatings(df_ratings,dense_shape)->SparseTensor:\n",
    "    \"\"\"\n",
    "    This is the matrix to predict\n",
    "    Simplify a big matrix into a tensor\n",
    "    \"\"\"\n",
    "    indices = df_ratings[[\"user\", \"item\"]].values\n",
    "    values = df_ratings[\"rating\"].values\n",
    "    return SparseTensor(\n",
    "      indices=indices,\n",
    "      values=values,\n",
    "      dense_shape=dense_shape)\n",
    "\n",
    "def sparse_mean_square_error(user_embeddings, item_embeddings, sparse_ratings):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    sparse_ratings: A SparseTensor rating matrix, of dense_shape [N, M]\n",
    "    user_embeddings: A dense Tensor U of shape [N, k] where k is the embedding\n",
    "      dimension, such that U_i is the embedding of user i.\n",
    "    item_embeddings: A dense Tensor V of shape [M, k] where k is the embedding\n",
    "      dimension, such that V_j is the embedding of item j.\n",
    "    Returns:\n",
    "    A scalar Tensor representing the MSE between the true ratings and the\n",
    "      model's predictions.\n",
    "    \"\"\"\n",
    "\n",
    "    predictions = tf.reduce_sum(  # de los indices usuario movie creatods, los usa para obtener de los datos verdaderos\n",
    "      tf.gather(user_embeddings, sparse_ratings.indices[:, 0]) *\n",
    "      tf.gather(item_embeddings, sparse_ratings.indices[:, 1]),\n",
    "      axis=1)\n",
    "\n",
    "    loss = tf.reduce_sum(tf.add(sparse_ratings.values, - predictions) ** 2) / tf.cast(predictions.shape[0], tf.float32)  # mean squared error\n",
    "    return loss\n",
    "\n",
    "\n",
    "\n",
    "class CFModel(object):\n",
    "\n",
    "  \"\"\"Simple class that represents a collaborative filtering model\"\"\"\n",
    "\n",
    "  def __init__(self, embedding_vars):\n",
    "    \"\"\"Initializes a CFModel.\n",
    "    Args:\n",
    "      embedding_vars: A dictionary of tf.Variables.\n",
    "      loss: A float Tensor. The loss to optimize.\n",
    "      metrics: optional list of dictionaries of Tensors. The metrics in each\n",
    "        dictionary will be plotted in a separate figure during training.\n",
    "    \"\"\"\n",
    "    self._embedding_vars = embedding_vars\n",
    "    self._embeddings = {k: None for k in embedding_vars}\n",
    "\n",
    "\n",
    "  @property\n",
    "  def embeddings(self):\n",
    "    \"\"\"The embeddings dictionary.\"\"\"\n",
    "    return self._embeddings\n",
    "\n",
    "  def train(self, tensor_train, num_iterations=20, learning_rate=0.01, optimizer=tf.keras.optimizers.SGD, verbosity=1):  # tf.keras.optimizers.SGD() tensorflow 2 = tf.train.GradientDescentOptimizer  tensorflow 1\n",
    "    \"\"\"Trains the model.\n",
    "    Args:\n",
    "      iterations: number of iterations to run.\n",
    "      learning_rate: optimizer learning rate.\n",
    "      plot_results: whether to plot the results at the end of training.\n",
    "      optimizer: the optimizer to use. Default to GradientDescentOptimizer.\n",
    "    \"\"\"\n",
    "\n",
    "    U = self._embedding_vars['user']\n",
    "    V = self._embedding_vars['item']\n",
    "    opt = optimizer(learning_rate=learning_rate)\n",
    "    var_list = [U, V]\n",
    "    loss_fn = lambda: sparse_mean_square_error(U, V, tensor_train)\n",
    "\n",
    "    debug_step = int(num_iterations/10)\n",
    "    # Train and append results.\n",
    "    for i in range(num_iterations + 1):  # tqdm(range(num_iterations + 1))\n",
    "        opt.minimize(loss_fn, var_list)\n",
    "        if i % debug_step == 0 or i == 0 or i==num_iterations:\n",
    "          print(\"Training error in iteration %i\" % i, sparse_mean_square_error(U, V, tensor_train))\n",
    "\n",
    "    for k, v in self._embedding_vars.items():\n",
    "        self._embeddings[k] = v.numpy()\n",
    "\n",
    "    return U, V\n",
    "\n",
    "  def candidateGeneration(self,user,k=3):\n",
    "    # user: id 0-index\n",
    "    scores = None\n",
    "    try:\n",
    "        scores = dot_product_with_norms_controlled(\n",
    "              self.embeddings[\"user\"][user], self.embeddings[\"item\"].T\n",
    "        )\n",
    "    except IndexError as e:\n",
    "        # no hay recomendaciones para ese usuario\n",
    "        return []\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"score\": list(scores),\n",
    "        'item': list(range(len(scores)))\n",
    "    })\n",
    "    \n",
    "    return df.sort_values([\"score\"], ascending=False)[\"item\"].values[0:k]\n",
    "\n",
    "  def predict(self, U, V):\n",
    "    return tf.matmul(U, V, transpose_b=True)\n",
    "\n",
    "\n",
    "\n",
    "def buildModel(df_ratings:pd.DataFrame, embedding_dim=30, init_stddev=1, num_iterations=500, learning_rate=0.03, verbosity=1):\n",
    "    \"\"\"\n",
    "    df_ratings: have columns [\"user\",\"item\",\"rating\"]\n",
    "    \"\"\"\n",
    "\n",
    "    dense_shape = [df_ratings[\"user\"].max()+1, df_ratings[\"item\"].max()+1]\n",
    "    # Split the ratings DataFrame into train and test.\n",
    "    X_test = df_ratings.sample(frac=0.2, replace=False).astype('float32')\n",
    "    X_train = df_ratings[~df_ratings.index.isin(X_test.index)].astype('float32')\n",
    "\n",
    "    # SparseTensor representation of the train and test datasets.\n",
    "    # Its for optimization\n",
    "    tensor_train = buildSparseTensorRatings(X_train,dense_shape)\n",
    "    tensor_test = buildSparseTensorRatings(X_test,dense_shape)\n",
    "\n",
    "\n",
    "    # Initialize the embeddings using a normal distribution.\n",
    "    U = tf.Variable(tf.random.normal([tensor_train.dense_shape[0], embedding_dim], stddev=init_stddev), dtype=\"float32\")  # stddev indicará que tan dispersos estarán los datos\n",
    "    V = tf.Variable(tf.random.normal([tensor_train.dense_shape[1], embedding_dim], stddev=init_stddev), dtype=\"float32\")  # mientras más alto estarán más dispersos\n",
    "\n",
    "    embeddings = {\n",
    "      \"user\": U,\n",
    "      \"item\": V\n",
    "    }\n",
    "\n",
    "    model = CFModel(embeddings)\n",
    "\n",
    "    U, V = model.train(tensor_train,num_iterations=num_iterations, learning_rate=learning_rate, verbosity=verbosity)\n",
    "\n",
    "    print(\"TEST LOSS\", sparse_mean_square_error(U, V, tensor_test))\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error in iteration 0 tf.Tensor(16.976624, shape=(), dtype=float32)\n",
      "Training error in iteration 10 tf.Tensor(12.1664715, shape=(), dtype=float32)\n",
      "Training error in iteration 20 tf.Tensor(8.755703, shape=(), dtype=float32)\n",
      "Training error in iteration 30 tf.Tensor(6.3272185, shape=(), dtype=float32)\n",
      "Training error in iteration 40 tf.Tensor(4.59147, shape=(), dtype=float32)\n",
      "Training error in iteration 50 tf.Tensor(3.346208, shape=(), dtype=float32)\n",
      "Training error in iteration 60 tf.Tensor(2.4494772, shape=(), dtype=float32)\n",
      "Training error in iteration 70 tf.Tensor(1.8012483, shape=(), dtype=float32)\n",
      "Training error in iteration 80 tf.Tensor(1.3307941, shape=(), dtype=float32)\n",
      "Training error in iteration 90 tf.Tensor(0.987953, shape=(), dtype=float32)\n",
      "Training error in iteration 100 tf.Tensor(0.73703706, shape=(), dtype=float32)\n",
      "TEST LOSS tf.Tensor(27.920563, shape=(), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 0, 1])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = buildModel(df_ratings,\n",
    "            embedding_dim=30,\n",
    "            init_stddev=1,\n",
    "            num_iterations=100,\n",
    "            learning_rate=0.001,)\n",
    "\n",
    "model.candidateGeneration(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a3c2402a762b1da2b664ca9cbb9344946d41b73132102685c4db1aa6c02b5b44"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
