{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='top'></a>\n",
    "<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n",
    "<p style=\"background-color:#682F2F;font-family:newtimeroman;color:#FFF9ED;font-size:150%;text-align:center;border-radius:10px 10px;\">TABLE OF CONTENTS</p>\n",
    "\n",
    "* [1. IMPORTING LIBRARIES](#1)\n",
    "* [2. LOADING DATA](#2)    \n",
    "* [3. DATA PIPELINE](#3) (Maleable section)\n",
    "* [4. EXPLORATORY DATA ANALYSIS](#4)     \n",
    "* [5. MODELING](#5)\n",
    "* [6. EVALUATION](#6)\n",
    "* [7. DISCUSSION](#7)  \n",
    "* [8. DEPLOYMENT AND ENSEMBLES](#8)\n",
    "* [9. END](#9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "# <p style=\"background-color:#682F2F;font-family:newtimeroman;color:#FFF9ED;font-size:150%;text-align:center;border-radius:10px 10px;\">IMPORTING LIBRARIES</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "path_root = \"/home/magody/programming/python/data_science/\"\n",
    "path_output = f\"{path_root}output/\"\n",
    "path_data = f\"{path_root}data/movies/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Basic Operations\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-surprise\n",
    "# Lets Import the Data Import into the Surprise Reader\n",
    "from surprise import Dataset, Reader\n",
    "from surprise import KNNWithMeans\n",
    "from surprise.model_selection import  cross_validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "# <p style=\"background-color:#682F2F;font-family:newtimeroman;color:#FFF9ED;font-size:150%;text-align:center;border-radius:10px 10px;\">LOADING DATA</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies:pd.DataFrame = pd.read_csv(f\"{path_data}movies.csv\")\n",
    "# lets also check the ratings dataset\n",
    "ratings:pd.DataFrame  = pd.read_csv(f\"{path_data}ratings.csv\")\n",
    "# Removing the Timestamp column from the Data, as the Surprise Library Accepts only three Columns\n",
    "ratings = ratings.drop(['timestamp'], axis = 1)\n",
    "\n",
    "file_path = f\"{path_data}ratings_modified.csv\"\n",
    "\n",
    "# Now, we have to Create a CSV File for the new rating data, as the Surprise Library can only accept CSV Files as Input\n",
    "# We will have to Specify the Header as None, as again the Surprise Library cannot take in Column Names\n",
    "# We will have to set the Index also as False, Becaus ethe Surprise Library cannot Handle Indexes also.\n",
    "ratings.to_csv(file_path, \n",
    "               header = None,\n",
    "               index = False)\n",
    "x = pd.read_csv(file_path)\n",
    "x.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets First Specify the File Path and Reader Parameters Required for Loading the Data\n",
    "\n",
    "reader = Reader(line_format='user item rating', sep=',', rating_scale = (1,5))\n",
    "\n",
    "# Lets Load the Dataset into the Surprise Reader, We cannot read this Dataset, as this is a Surprise Object. \n",
    "data = Dataset.load_from_file(file_path, reader=reader)\n",
    "\n",
    "# Lets Build the Training Dataset\n",
    "train = data.build_full_trainset()\n",
    "\n",
    "# lets get the Number of Users and Items\n",
    "print('Number of users in the Database :', train.n_users)\n",
    "print('Number of items in the Database :', train.n_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eager explotarion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(movies.shape, ratings.shape)\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a>\n",
    "# <p style=\"background-color:#682F2F;font-family:newtimeroman;color:#FFF9ED;font-size:150%;text-align:center;border-radius:10px 10px;\">DATA PIPELINE</p>\n",
    "- Special section: is used before and after by the following sections. Isn't in the common sequential flow.\n",
    "- Maleable section.\n",
    "- Here we define a pipeline for cleaning, preprocessing, dimensionality reduction, feature enginering, etc. That can be modified at any time for other following steps.\n",
    "- Commonly, we use the insights got in EDA for write this part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a>\n",
    "# <p style=\"background-color:#682F2F;font-family:newtimeroman;color:#FFF9ED;font-size:150%;text-align:center;border-radius:10px 10px;\">EXPLORATORY DATA ANALYSIS</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration and understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of data prepared for consumption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivoting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA\n",
    "- Principal component analysis (PCA) is a technique for reducing the dimensionality of such datasets, increasing interpretability but at the same time minimizing information loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5\"></a>\n",
    "# <p style=\"background-color:#682F2F;font-family:newtimeroman;color:#FFF9ED;font-size:150%;text-align:center;border-radius:10px 10px;\">MODELING</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User Based collaborative Filtering.\n",
    "my_sim_option = {'name':'pearson', 'user_based':True}\n",
    "\n",
    "# KNN model as backend \n",
    "algo = KNNWithMeans(k = 15, min_k = 5, \n",
    "    sim_options = my_sim_option, verbose = True\n",
    "    )\n",
    "\n",
    "# Lets Training the Model on our Dataset\n",
    "algo.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"6\"></a>\n",
    "# <p style=\"background-color:#682F2F;font-family:newtimeroman;color:#FFF9ED;font-size:150%;text-align:center;border-radius:10px 10px;\">EVALUATION</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation \n",
    "results = cross_validate(algo = algo, \n",
    "                         data = data, \n",
    "                         measures=['RMSE'], \n",
    "                         cv = 5, \n",
    "                         return_train_measures=True)\n",
    "    \n",
    "print(results['test_rmse'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"7\"></a>\n",
    "# <p style=\"background-color:#682F2F;font-family:newtimeroman;color:#FFF9ED;font-size:150%;text-align:center;border-radius:10px 10px;\">DISCUSSION</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patterns study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"8\"></a>\n",
    "# <p style=\"background-color:#682F2F;font-family:newtimeroman;color:#FFF9ED;font-size:150%;text-align:center;border-radius:10px 10px;\">DEPLOYMENT AND ENSEMBLES</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets Create a Dictionary to Map the Movie Id and Movie Names\n",
    "movie_id_to_title_map = {}\n",
    "\n",
    "for m_id , title in zip(movies['movieId'].values , movies['title'].values):\n",
    "    movie_id_to_title_map[str(m_id)] = title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realtime prediction\n",
    "\n",
    "# how much the user id - 1 would rate item id 31 ?\n",
    "val = algo.predict(uid = '1', iid = '31')\n",
    "print(val)\n",
    "print(movie_id_to_title_map[val[1]] , val[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n(predictions, n=10):\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n\n",
    "\n",
    "# Lets Create a Function to Fetch all the Movies Watched by the Users \n",
    "def PreviousMoviedUserWatched(user_df , user_id , item_map):\n",
    "    user_df = user_df[user_df.iloc[: , 0] == user_id]\n",
    "    for movie , rating in zip(user_df.iloc[:,1].values , user_df.iloc[:,2].values):\n",
    "        print(item_map[str(movie)] , rating)\n",
    "\n",
    "# Lets Create a Function to Predict Movies to the Users based on the Movies Watched Previously\n",
    "def UserPredictions(user_id , top_n , item_map):\n",
    "    print(\"Predictions for User Id : \" , user_id)\n",
    "    user_ratings = top_n[user_id]\n",
    "    for item_id , rating in user_ratings :\n",
    "        print(item_map[item_id] , \" : \" , rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build an Iterable Testset, Direct predictions on Train would throw errors \n",
    "\n",
    "testdata = train.build_anti_testset() # all the data not related to the user\n",
    "predictions = algo.test(testdata)\n",
    "top_n = get_top_n(predictions, n = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PreviousMoviedUserWatched(ratings , 1 , movie_id_to_title_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UserPredictions('1' , top_n , movie_id_to_title_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"9\"></a>\n",
    "# <p style=\"background-color:#682F2F;font-family:newtimeroman;color:#FFF9ED;font-size:150%;text-align:center;border-radius:10px 10px;\">END</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Return to table of contents](#top)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a3c2402a762b1da2b664ca9cbb9344946d41b73132102685c4db1aa6c02b5b44"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
