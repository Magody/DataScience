{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get helper_functions.py script from course GitHub\n",
    "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py \n",
    "\n",
    "# Import helper functions we're going to use\n",
    "from helper_functions import create_tensorboard_callback, plot_loss_curves, unzip_data, walk_through_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 10% of the data of the 10 classes\n",
    "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip \n",
    "\n",
    "unzip_data(\"10_food_classes_10_percent.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and test directories\n",
    "train_dir = \"10_food_classes_10_percent/train/\"\n",
    "test_dir = \"10_food_classes_10_percent/test/\"\n",
    "# Create data inputs\n",
    "import tensorflow as tf\n",
    "IMG_SIZE = (224, 224) # define image size\n",
    "train_data_10_percent = tf.keras.preprocessing.image_dataset_from_directory(directory=train_dir,\n",
    "                                                                            image_size=IMG_SIZE,\n",
    "                                                                            label_mode=\"categorical\", # what type are the labels?\n",
    "                                                                            batch_size=32) # batch_size is 32 by default, this is generally a good number\n",
    "test_data_10_percent = tf.keras.preprocessing.image_dataset_from_directory(directory=test_dir,\n",
    "                                                                           image_size=IMG_SIZE,\n",
    "                                                                           label_mode=\"categorical\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create base model with tf.keras.applications\n",
    "base_model = tf.keras.applications.EfficientNetB0(include_top=False)\n",
    "\n",
    "# 2. Freeze the base model (so the pre-learned patterns remain)\n",
    "base_model.trainable = False\n",
    "\n",
    "# 3. Create inputs into the base model\n",
    "inputs = tf.keras.layers.Input(shape=(224, 224, 3), name=\"input_layer\")\n",
    "\n",
    "# 4. If using ResNet50V2, add this to speed up convergence, remove for EfficientNet\n",
    "# x = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)(inputs)\n",
    "\n",
    "# 5. Pass the inputs to the base_model (note: using tf.keras.applications, EfficientNet inputs don't have to be normalized)\n",
    "x = base_model(inputs)\n",
    "# Check data shape after passing it to base_model\n",
    "print(f\"Shape after base_model: {x.shape}\")\n",
    "\n",
    "# 6. Average pool the outputs of the base model (aggregate all the most important information, reduce number of computations)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D(name=\"global_average_pooling_layer\")(x)\n",
    "print(f\"After GlobalAveragePooling2D(): {x.shape}\")\n",
    "\n",
    "# 7. Create the output activation layer\n",
    "outputs = tf.keras.layers.Dense(10, activation=\"softmax\", name=\"output_layer\")(x)\n",
    "\n",
    "# 8. Combine the inputs with the outputs into a model\n",
    "model_0 = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# 9. Compile the model\n",
    "model_0.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# 10. Fit the model (we use less steps for validation so it's faster)\n",
    "history_10_percent = model_0.fit(train_data_10_percent,\n",
    "                                 epochs=5,\n",
    "                                 steps_per_epoch=len(train_data_10_percent),\n",
    "                                 validation_data=test_data_10_percent,\n",
    "                                 # Go through less of the validation data so epochs are faster (we want faster experiments!)\n",
    "                                 validation_steps=int(0.25 * len(test_data_10_percent)), \n",
    "                                 # Track our model's training logs for visualization later\n",
    "                                 callbacks=[create_tensorboard_callback(\"transfer_learning\", \"10_percent_feature_extract\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = True\n",
    "\n",
    "# Freeze all layers except for the last 10\n",
    "for layer in base_model.layers[:-10]:\n",
    "  layer.trainable = False\n",
    "# Every change we made, we recompile\n",
    "# Recompile the model (always recompile after any adjustments to a model)\n",
    "model_0.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=tf.keras.optimizers.Adam(lr=0.0001), # lr is 10x lower than before for fine-tuning\n",
    "              metrics=[\"accuracy\"])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
